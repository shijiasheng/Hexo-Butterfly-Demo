<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>SoftwareEngineering | 平凡的世界</title><meta name="author" content="Shi Jiasheng"><meta name="copyright" content="Shi Jiasheng"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="1.需求分析目前的政治事件语料存在提取出来的事件是无关事件而导致的质量参差不齐的状况。如一篇常见的新闻内容，会在内容中简明扼要的讲述主要事件，然后引述多人对于该事件评论或者讲述一些相关事件，那么目前的语料系统会很大可能将该新闻内容归纳为评论类或者别的类别的事件。 综上，需要对于政治事件语料进行筛选，选出质量更高的事件语料。 2.解决思路现有的语料中，确定的eventtext即触发词需要判断其是否有">
<meta property="og:type" content="article">
<meta property="og:title" content="SoftwareEngineering">
<meta property="og:url" content="http://shijiasheng.top/2021/01/11/SoftwareEngineering/index.html">
<meta property="og:site_name" content="平凡的世界">
<meta property="og:description" content="1.需求分析目前的政治事件语料存在提取出来的事件是无关事件而导致的质量参差不齐的状况。如一篇常见的新闻内容，会在内容中简明扼要的讲述主要事件，然后引述多人对于该事件评论或者讲述一些相关事件，那么目前的语料系统会很大可能将该新闻内容归纳为评论类或者别的类别的事件。 综上，需要对于政治事件语料进行筛选，选出质量更高的事件语料。 2.解决思路现有的语料中，确定的eventtext即触发词需要判断其是否有">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg">
<meta property="article:published_time" content="2021-01-11T04:01:34.000Z">
<meta property="article:modified_time" content="2021-01-11T04:02:34.947Z">
<meta property="article:author" content="Shi Jiasheng">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg"><link rel="shortcut icon" href="https://i.loli.net/2020/10/17/oNFSnzUL5H71cQi.jpg"><link rel="canonical" href="http://shijiasheng.top/2021/01/11/SoftwareEngineering/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><script>var GLOBAL_CONFIG = { 
  root: '/',
  hexoversion: '5.2.0',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true},
  copy: {
    success: 'Copy successfully',
    error: 'Copy error',
    noSupport: 'The browser does not support'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: 'days',
  date_suffix: {
    just: 'Just',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  ClickShowText: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  justifiedGallery: {
    js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
    css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
};

var saveToLocal = {
  set: function setWithExpiry(key, value, ttl) {
    const now = new Date()
    const expiryDay = ttl * 86400000
    const item = {
      value: value,
      expiry: now.getTime() + expiryDay,
    }
    localStorage.setItem(key, JSON.stringify(item))
  },

  get: function getWithExpiry(key) {
    const itemStr = localStorage.getItem(key)

    if (!itemStr) {
      return undefined
    }
    const item = JSON.parse(itemStr)
    const now = new Date()

    if (now.getTime() > item.expiry) {
      localStorage.removeItem(key)
      return undefined
    }
    return item.value
  }
}</script><script id="config_change">var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isSidebar: true,
  postUpdate: '2021-01-11 12:02:34'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(function () {
  window.activateDarkMode = function () {
    document.documentElement.setAttribute('data-theme', 'dark')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
    }
  }
  window.activateLightMode = function () {
    document.documentElement.setAttribute('data-theme', 'light')
    if (document.querySelector('meta[name="theme-color"]') !== null) {
      document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
    }
  }

  const autoChangeMode = 'false'
  const t = saveToLocal.get('theme')
  if (autoChangeMode === '1') {
    const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
    const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
    const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
    const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

    if (t === undefined) {
      if (isLightMode) activateLightMode()
      else if (isDarkMode) activateDarkMode()
      else if (isNotSpecified || hasNoSupport) {
        const now = new Date()
        const hour = now.getHours()
        const isNight = hour <= 6 || hour >= 18
        isNight ? activateDarkMode() : activateLightMode()
      }
      window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
        if (saveToLocal.get('theme') === undefined) {
          e.matches ? activateDarkMode() : activateLightMode()
        }
      })
    } else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else if (autoChangeMode === '2') {
    const now = new Date()
    const hour = now.getHours()
    const isNight = hour <= 6 || hour >= 18
    if (t === undefined) isNight ? activateDarkMode() : activateLightMode()
    else if (t === 'light') activateLightMode()
    else activateDarkMode()
  } else {
    if (t === 'dark') activateDarkMode()
    else if (t === 'light') activateLightMode()
  }
})()</script><meta name="generator" content="Hexo 5.2.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">Loading...</div></div></div><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="https://i.loli.net/2020/10/17/oNFSnzUL5H71cQi.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">Articles</div><div class="length_num">7</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div></div></div><div id="body-wrap"><div id="sidebar"><i class="fas fa-arrow-right on" id="toggle-sidebar"></i><div class="sidebar-toc"><div class="sidebar-toc__title">Catalog</div><div class="sidebar-toc__progress"><span class="progress-notice">You've read</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1-%E9%9C%80%E6%B1%82%E5%88%86%E6%9E%90"><span class="toc-number">1.</span> <span class="toc-text">1.需求分析</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2-%E8%A7%A3%E5%86%B3%E6%80%9D%E8%B7%AF"><span class="toc-number">2.</span> <span class="toc-text">2.解决思路</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3-%E5%85%B7%E4%BD%93%E8%A7%A3%E5%86%B3%E6%AD%A5%E9%AA%A4"><span class="toc-number">3.</span> <span class="toc-text">3.具体解决步骤</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">3.1.</span> <span class="toc-text">3.1数据预处理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2%E6%80%9D%E8%B7%AF%E4%B8%80%EF%BC%88%E5%8A%A8%E8%AF%8D%E5%AD%97%E5%85%B8%EF%BC%89"><span class="toc-number">3.2.</span> <span class="toc-text">3.2思路一（动词字典）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-1%E9%A2%84%E5%A4%84%E7%90%86%E5%8A%A8%E8%AF%8D%E5%AD%97%E5%85%B8"><span class="toc-number">3.2.1.</span> <span class="toc-text">3.2.1预处理动词字典</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-2%E4%BD%BF%E7%94%A8%E5%8A%A8%E8%AF%8D%E5%AD%97%E5%85%B8"><span class="toc-number">3.2.2.</span> <span class="toc-text">3.2.2使用动词字典</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3%E6%80%9D%E8%B7%AF%E4%BA%8C%EF%BC%88%E8%AF%8D%E5%90%91%E9%87%8F%E6%A8%A1%E5%9E%8B%EF%BC%89"><span class="toc-number">3.3.</span> <span class="toc-text">3.3思路二（词向量模型）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-1%E9%A2%84%E8%AE%AD%E7%BB%83%E8%AF%8D%E5%90%91%E9%87%8F%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.3.1.</span> <span class="toc-text">3.3.1预训练词向量模型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-2%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.3.2.</span> <span class="toc-text">3.3.2使用词向量模型</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4%E7%BB%9F%E4%B8%80%E6%B5%81%E7%A8%8B"><span class="toc-number">3.4.</span> <span class="toc-text">3.4统一流程</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-1%E5%8A%A8%E8%AF%8D%E8%AF%8D%E5%85%B8"><span class="toc-number">3.4.1.</span> <span class="toc-text">3.4.1动词词典</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-2%E8%AF%8D%E5%90%91%E9%87%8F%E6%A8%A1%E5%9E%8B"><span class="toc-number">3.4.2.</span> <span class="toc-text">3.4.2词向量模型</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E4%BC%AA%E4%BB%A3%E7%A0%81"><span class="toc-number">4.</span> <span class="toc-text">4.伪代码</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5-%E4%BC%98%E5%8C%96%E6%97%A5%E5%BF%97"><span class="toc-number">5.</span> <span class="toc-text">5.优化日志</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6-%E7%BB%93%E6%9E%9C%E6%B1%87%E6%80%BB"><span class="toc-number">6.</span> <span class="toc-text">6.结果汇总</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#6-1-%E4%BA%BA%E5%B7%A5%E6%A0%87%E8%AE%B0"><span class="toc-number">6.1.</span> <span class="toc-text">6.1 人工标记</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-2-%E6%95%B0%E6%8D%AE%E5%8C%B9%E9%85%8D%E4%B8%8E%E9%98%88%E5%80%BC%E7%AD%9B%E9%80%89"><span class="toc-number">6.2.</span> <span class="toc-text">6.2 数据匹配与阈值筛选</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-3-%E4%B8%A4%E7%A7%8D%E6%96%B9%E6%B3%95%E7%BB%93%E5%90%88"><span class="toc-number">6.3.</span> <span class="toc-text">6.3 两种方法结合</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-4-%E7%AD%9B%E9%80%89%E7%BB%93%E6%9E%9C"><span class="toc-number">6.4.</span> <span class="toc-text">6.4 筛选结果</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-4-1-%E6%96%B0%E9%97%BB%E4%BA%8B%E4%BB%B6%E4%B8%AD%E8%AF%84%E8%AE%BA%E8%BF%87%E5%A4%9A%EF%BC%8C%E8%A2%AB%E8%AE%A4%E4%B8%BA%E6%98%AF%E8%AF%84%E8%AE%BA%E7%B1%BB%E6%96%B0%E9%97%BB%EF%BC%8C%E5%AE%9E%E5%88%99%E4%B8%8D%E7%84%B6%E3%80%82"><span class="toc-number">6.5.</span> <span class="toc-text">6.4.1 新闻事件中评论过多，被认为是评论类新闻，实则不然。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-4-2-%E8%A7%A6%E5%8F%91%E8%AF%8D%E6%8F%90%E5%8F%96%E4%B8%8D%E5%87%86%E7%A1%AE%EF%BC%8C%E4%B8%8D%E5%85%B7%E5%A4%87%E7%8B%AC%E7%89%B9%E6%80%A7%E3%80%82"><span class="toc-number">6.6.</span> <span class="toc-text">6.4.2 触发词提取不准确，不具备独特性。</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-4-3-%E7%94%B1%E4%BA%8E%E8%AF%AD%E4%B9%89%E7%9A%84%E5%85%B3%E7%B3%BB%EF%BC%8C%E6%B2%A1%E6%9C%89%E6%AD%A3%E7%A1%AE%E8%AF%86%E5%88%AB%E6%83%85%E6%84%9F%E5%8F%96%E5%90%91%EF%BC%8C%E9%94%99%E5%B0%86%E7%9B%B8%E5%8F%8D%E7%9A%84%E6%83%85%E6%84%9F%E5%8F%96%E5%90%91%E6%8F%90%E5%8F%96%E3%80%82"><span class="toc-number">6.7.</span> <span class="toc-text">6.4.3 由于语义的关系，没有正确识别情感取向，错将相反的情感取向提取。</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7-%E5%AE%9E%E9%AA%8C%E5%AE%A4%E5%85%B6%E4%BB%96%E5%AD%A6%E4%B9%A0%E6%88%90%E6%9E%9C"><span class="toc-number">7.</span> <span class="toc-text">7.实验室其他学习成果</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#7-1-TextCNN"><span class="toc-number">7.1.</span> <span class="toc-text">7.1 TextCNN</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-2-Ziyun"><span class="toc-number">7.2.</span> <span class="toc-text">7.2 Ziyun</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-3-flask"><span class="toc-number">7.3.</span> <span class="toc-text">7.3 flask</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#8-%E6%96%87%E4%BB%B6%E8%AF%B4%E6%98%8E"><span class="toc-number">8.</span> <span class="toc-text">8.文件说明</span></a></li></ol></div></div></div><header class="post-bg" id="page-header" style="background-image: url(https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">平凡的世界</a></span><span id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> About</span></a></div></div><span class="close" id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></span></span></nav><div id="post-info"><div id="post-title"><div class="posttitle">SoftwareEngineering</div></div><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2021-01-11T04:01:34.000Z" title="Created 2021-01-11 12:01:34">2021-01-11</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2021-01-11T04:02:34.947Z" title="Updated 2021-01-11 12:02:34">2021-01-11</time></span></div><div class="meta-secondline"> <span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post View:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout_post" id="content-inner"><article id="post"><div class="post-content" id="article-container"><h1 id="1-需求分析"><a href="#1-需求分析" class="headerlink" title="1.需求分析"></a>1.需求分析</h1><p>目前的政治事件语料存在提取出来的事件是无关事件而导致的质量参差不齐的状况。如一篇常见的新闻内容，会在内容中简明扼要的讲述主要事件，然后引述多人对于该事件评论或者讲述一些相关事件，那么目前的语料系统会很大可能将该新闻内容归纳为评论类或者别的类别的事件。</p>
<p>综上，需要对于政治事件语料进行筛选，选出质量更高的事件语料。</p>
<h1 id="2-解决思路"><a href="#2-解决思路" class="headerlink" title="2.解决思路"></a>2.解决思路</h1><p>现有的语料中，确定的eventtext即触发词需要判断其是否有效，本章节主要为判断其触发词的有效性从而来获取判断语料的质量高低。前文已经选择TextRank可以对于文章的关键词进行提取，则我们需要通过触发词和TextRank的关键词进行匹配，匹配的结果决定了判断政治事件语料质量高低的结果。</p>
<p>TextRank相当于是给予文章中的每一个词进行打分，采用分高的选取为关键词。所以我们最终采用的方式是根据句子的长度来匹配TextRank的长度。可以很好的解决字数过长而导致的评分相对过高的问题和语料中少量的事件文章重复的问题。如1000字生成11个关键词，每多100字增加1个关键词。（因为eventtext的个数和文章的多少有关。）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_textrank</span>(<span class="params">txt</span>):</span></span><br><span class="line">    tr4w = TextRank4Keyword()</span><br><span class="line">    tr4w.analyze(text=txt, lower=<span class="literal">True</span>, window=<span class="number">2</span>)  <span class="comment"># py2中text必须是utf8编码的str或者unicode对象，py3中必须是utf8编码的bytes或者str对象</span></span><br><span class="line">    len_textrank = round(len(txt) / <span class="number">1000</span> * <span class="number">10</span>) + <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> tr4w.get_keywords(len_textrank, word_min_len=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h1 id="3-具体解决步骤"><a href="#3-具体解决步骤" class="headerlink" title="3.具体解决步骤"></a>3.具体解决步骤</h1><h2 id="3-1数据预处理"><a href="#3-1数据预处理" class="headerlink" title="3.1数据预处理"></a>3.1数据预处理</h2><p>首先我们循环获取每一个单独的语料，语料中包括：新闻内容，预料判断出来的content，source，target，eventtext，eventroot。其中新闻的内容由于是人民日报的很规范的内容，每个新闻的第一句是这篇新闻的标题。首先根据连续的三个“NULL”将新闻截取出来，将新闻通过空格截断从而获取第一句话即新闻标题。从而获取了所有的语料需要获取的内容。</p>
<h2 id="3-2思路一（动词字典）"><a href="#3-2思路一（动词字典）" class="headerlink" title="3.2思路一（动词字典）"></a>3.2思路一（动词字典）</h2><p>本思路为通过动词词典即eventroot的汇总进行对于词汇的匹配，即对于同一种eventroot类型，我们有这一类型的不同的触发词，若触发词和关键词属于同一个类型，则认为匹配成功。</p>
<h3 id="3-2-1预处理动词字典"><a href="#3-2-1预处理动词字典" class="headerlink" title="3.2.1预处理动词字典"></a>3.2.1预处理动词字典</h3><p>由于动词词典是.txt文件，且在归类中还存在同一个词汇从属于不同类别的情况，需要对于动词词典进行预处理。代码详见<strong>create_dictionary.py</strong>。</p>
<h3 id="3-2-2使用动词字典"><a href="#3-2-2使用动词字典" class="headerlink" title="3.2.2使用动词字典"></a>3.2.2使用动词字典</h3><p>在将动词词典（约1200个动词）变成csv文件格式之后（格式为词对应着一个属于类的类别序号），如果需要某个词，对于这个词，它从属的所有的类别都将作为参考的价值，所以可以从这个词向量中获取调用这个词汇属于所有类别的集合。</p>
<h2 id="3-3思路二（词向量模型）"><a href="#3-3思路二（词向量模型）" class="headerlink" title="3.3思路二（词向量模型）"></a>3.3思路二（词向量模型）</h2><p>本思路的出发为对于词语的匹配，需要有相似度的匹配，如果采用字词作为标准则会出现只存在有或无，0或1的问题，那么将不利于更加细致地处理匹配结果，所以决定采用通过词向量模型辅助词语的匹配。</p>
<h3 id="3-3-1预训练词向量模型"><a href="#3-3-1预训练词向量模型" class="headerlink" title="3.3.1预训练词向量模型"></a>3.3.1预训练词向量模型</h3><p>本次词向量模型主要通过word2vec的方法来对于所有词汇赋予其独有的词向量。word2vec这种方法是当今相对比较热门的算法，它通过神经网络机器学习算法来训练N-gram语言模型，并在训练过程中求出word所对应的vector的方法。</p>
<p>所以对于这个思路，首先，我们需要把所有的政治事件语料进行合并，也就是我们训练模型需要将所有的语料内容（约35000篇文章）放入训练。但对于训练word2vec词向量而言，其实这个数据量相对还是小了一些。</p>
<p>针对所有的文章，首先采用jieba分词，对于文章进行分割（考虑到句子之间的关系有一部分体现在关系介词等联系上下文语句的词汇和一些基本词汇上，我们不删除停用词，）然后将所有的文章投喂到word2vec后，形成一个庞大的模型，这个模型中有对于每个词汇的独有的词向量。</p>
<p>word2vec学习资料：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/56343249">https://zhuanlan.zhihu.com/p/56343249</a></p>
<h3 id="3-3-2使用词向量模型"><a href="#3-3-2使用词向量模型" class="headerlink" title="3.3.2使用词向量模型"></a>3.3.2使用词向量模型</h3><p>word2vec生成的模型可以通过调用相似度函数来测试两个词汇之间的相似度，表示两个词汇之间的关系，判断其相似度。相似度的分布区间为0到1,0代表完全不相似，1代表完全相同，相似度越高，代表这两个词相关性越高。或者可以测试一些词之间的更高级的关系。如：Embedding(“皇帝”)-Embedding(“男”)=Embedding(“皇后”)-Embedding(“女”)。</p>
<h2 id="3-4统一流程"><a href="#3-4统一流程" class="headerlink" title="3.4统一流程"></a>3.4统一流程</h2><p>首先针对每一篇文章，获取文章内容和eventtext和eventroot。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_information</span>(<span class="params">file_in</span>):</span></span><br><span class="line">    text_in = open(file_in, <span class="string">&#x27;rb&#x27;</span>).read()</span><br><span class="line">    <span class="comment"># 文章截取出来</span></span><br><span class="line">    clean_text = text_in.split(<span class="string">b&#x27;NULL&#x27;</span>, <span class="number">-1</span>)</span><br><span class="line">    keywords = clean_text[<span class="number">8</span>]</span><br><span class="line">    clean_keywords = keywords.split(<span class="string">b&#x27;\n&#x27;</span>, <span class="number">-1</span>)</span><br><span class="line">    size_clean_keywords = int((len(clean_keywords) - <span class="number">11</span>) / <span class="number">9</span> + <span class="number">1</span>)</span><br><span class="line">    eventtext_in = []</span><br><span class="line">    source_in = []</span><br><span class="line">    target_in = []</span><br><span class="line">    event_root_in = []</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> range(size_clean_keywords):</span><br><span class="line">        eventtext_in.append(clean_keywords[<span class="number">8</span> + j * <span class="number">9</span>].replace(bytes(<span class="string">&#x27;eventtext\t&#x27;</span>.encode(<span class="string">&#x27;utf-8&#x27;</span>)), bytes(<span class="string">&#x27;&#x27;</span>.encode(<span class="string">&#x27;utf-8&#x27;</span>))))</span><br><span class="line">        source_in.append(clean_keywords[<span class="number">6</span> + j * <span class="number">9</span>].replace(bytes(<span class="string">&#x27;Source\t&#x27;</span>.encode(<span class="string">&#x27;utf-8&#x27;</span>)), bytes(<span class="string">&#x27;&#x27;</span>.encode(<span class="string">&#x27;utf-8&#x27;</span>))))</span><br><span class="line">        target_in.append(clean_keywords[<span class="number">7</span> + j * <span class="number">9</span>].replace(bytes(<span class="string">&#x27;Target\t&#x27;</span>.encode(<span class="string">&#x27;utf-8&#x27;</span>)), bytes(<span class="string">&#x27;&#x27;</span>.encode(<span class="string">&#x27;utf-8&#x27;</span>))))</span><br><span class="line">        event_root_in.append(clean_keywords[<span class="number">9</span> + j * <span class="number">9</span>].replace(bytes(<span class="string">&#x27;eventroot\t&#x27;</span>.encode(<span class="string">&#x27;utf-8&#x27;</span>)), bytes(<span class="string">&#x27;&#x27;</span>.encode(<span class="string">&#x27;utf-8&#x27;</span>))))</span><br><span class="line">    article = clean_text[<span class="number">6</span>]</span><br><span class="line">    result_in = clean_text[<span class="number">8</span>]</span><br><span class="line">    text = article.decode(<span class="string">&quot;utf-8&quot;</span>).split(<span class="string">&#x27;\u3000\u3000&#x27;</span>)</span><br><span class="line">    title_in = text[<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># print(article.decode(&quot;utf8&quot;))</span></span><br><span class="line">    <span class="comment"># text = text.decode(&quot;utf8&quot;).split(&#x27; &#x27;)</span></span><br><span class="line">    <span class="comment"># print(article.decode(&quot;utf8&quot;))</span></span><br><span class="line">    <span class="comment"># print(article.decode(&quot;utf8&quot;).strip(&#x27;\t&#x27;).strip(&#x27;\r&#x27;).replace(&#x27;\u3000\u3000&#x27;, &#x27; &#x27;))</span></span><br><span class="line">    clean_article_in = article.decode(<span class="string">&quot;utf-8&quot;</span>).strip(<span class="string">&#x27;\t&#x27;</span>).strip(<span class="string">&#x27;\r&#x27;</span>).replace(<span class="string">&#x27;\u3000\u3000&#x27;</span>, <span class="string">&#x27; &#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> clean_article_in, article, title_in, result_in, eventtext_in, source_in, target_in, event_root_in</span><br></pre></td></tr></table></figure>

<p>根据文章大小获取TextRank的关键词，词数的多少与文章大小有关。TextRank中每个关键词都有一个相应的匹配的权重，权重为TextRank所生成的，权重越高，则代表越接近最佳判断的关键词。</p>
<p>TextRank个人学习博客：<a href="https://shijiasheng.top/2020/11/05/TextRank/">https://shijiasheng.top/2020/11/05/TextRank/</a></p>
<h3 id="3-4-1动词词典"><a href="#3-4-1动词词典" class="headerlink" title="3.4.1动词词典"></a>3.4.1动词词典</h3><p>设$score$为最终得分，设$word$为TextRank关键字和event text触发词匹配上的词，设$weight$为$word$根据TextRank获得的相对于句子的权重。设$N$为匹配成功的个数，</p>
<p>$score=\sum_{i=0}^N weight(i)/N$</p>
<p>设最终得分为score=0。</p>
<p>将TextRank关键字和eventtext逐一比对，两两匹配，若匹配成功得分，score加上TextRank所求的关键字所对应的权重。</p>
<p>若这两个匹配的词汇中任意一个词不存在词向量模型中（即动词词典中没有记录该词），则匹配两个词汇是否在文字的字符串上匹配（匹配条件为，一个字符串是另一个字符串的子集）。</p>
<p>最终获取的score除以eventtext触发词的数量（相当于取平均值），为最终的结果。</p>
<p>（注：最终获取的score除以eventtext的数量的目的在于通过平均值的方式降低因为文章长度而匹配次数更高，从而分数更高的情况）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_score2</span>(<span class="params">eventtext, article_textrank, title_textrank, reader_words</span>):</span></span><br><span class="line">    score = <span class="number">0.00000000000</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    score = float(score)</span><br><span class="line">    event_text_count = len(eventtext)</span><br><span class="line">    clean_eventtext = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> title_textrank:</span><br><span class="line">        <span class="keyword">for</span> et <span class="keyword">in</span> eventtext:</span><br><span class="line">            et = et.decode(<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">            et = et.strip(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">            et = et.strip(<span class="string">&#x27;\r&#x27;</span>)</span><br><span class="line">            et = str(et)</span><br><span class="line">            <span class="keyword">if</span> item.word <span class="keyword">in</span> reader_words <span class="keyword">and</span> et <span class="keyword">in</span> reader_words:</span><br><span class="line">                item_word_number = []</span><br><span class="line">                et_number = []</span><br><span class="line">                <span class="keyword">for</span> row <span class="keyword">in</span> worddic:</span><br><span class="line">                    <span class="keyword">if</span> row[<span class="string">&#x27;name&#x27;</span>] == item.word:</span><br><span class="line">                        item_word_number.append(row[<span class="string">&#x27;number&#x27;</span>])</span><br><span class="line">                    <span class="keyword">if</span> row[<span class="string">&#x27;name&#x27;</span>] == et:</span><br><span class="line">                        et_number.append(row[<span class="string">&#x27;number&#x27;</span>])</span><br><span class="line">                <span class="comment"># print(item_word_number)</span></span><br><span class="line">                <span class="comment"># print(et_number)</span></span><br><span class="line">                <span class="keyword">if</span> set(item_word_number).issubset(set(et_number)) <span class="keyword">or</span> set(et_number).issubset(set(item_word_number)):</span><br><span class="line">                    <span class="comment"># print(&quot;TRUE\n&quot;)</span></span><br><span class="line">                    score = score + item.weight</span><br><span class="line">                    count = count + <span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> item.word == et:</span><br><span class="line">                    score = score + item.weight</span><br><span class="line">                    count = count + <span class="number">1</span></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> article_textrank:</span><br><span class="line">        <span class="keyword">for</span> et <span class="keyword">in</span> eventtext:</span><br><span class="line">            et = et.decode(<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">            et = et.strip(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">            et = et.strip(<span class="string">&#x27;\r&#x27;</span>)</span><br><span class="line">            et = str(et)</span><br><span class="line">            <span class="keyword">if</span> item.word <span class="keyword">in</span> model <span class="keyword">and</span> et <span class="keyword">in</span> model:</span><br><span class="line">                similarity = model.similarity(item.word, et)</span><br><span class="line">                <span class="keyword">if</span> similarity &gt;= <span class="number">0.5</span>:</span><br><span class="line">                    score = score + item.weight * similarity</span><br><span class="line">                    count = count + <span class="number">1</span></span><br><span class="line">                    clean_eventtext.append(et)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> item.word == et:</span><br><span class="line">                    score = score + item.weight</span><br><span class="line">                    count = count + <span class="number">1</span></span><br><span class="line">                    clean_eventtext.append(et)</span><br><span class="line">    <span class="keyword">if</span> event_text_count == <span class="number">0</span>:</span><br><span class="line">        score = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        score = score / event_text_count</span><br><span class="line">    clean_eventtext = np.unique(clean_eventtext)</span><br><span class="line">    <span class="keyword">return</span> score, event_text_count, count, clean_eventtext</span><br></pre></td></tr></table></figure>

<h3 id="3-4-2词向量模型"><a href="#3-4-2词向量模型" class="headerlink" title="3.4.2词向量模型"></a>3.4.2词向量模型</h3><p><strong>词向量模型公式：</strong></p>
<p>设$score$为最终得分，设$word$为TextRank关键字和event text触发词匹配上的词，设$weight$为$word$根据TextRank获得的相对于句子的权重，设$similarity$为TextRank关键字和event text触发词匹配的相似度，设$N$为匹配成功的个数。</p>
<p>$score=\sum_{i=0}^N weight(i)*similarity(i)/N$</p>
<p><strong>具体步骤：</strong></p>
<p>设最终得分为score=0。</p>
<p>将TextRank关键字和eventtext逐一比对，两两匹配，若匹配成功得分，score加上TextRank所求的关键字所对应的权重*两个词汇的相似度。</p>
<p>（注：经过最后测试，设定阈值为0.5，当两两匹配的相似度大于0.5时，认为匹配成功。）</p>
<p>若这两个匹配的词汇中任意一个词不存在词向量模型中（即模型中没有记录该词汇对应的词向量），则匹配两个词汇是否在文字的字符串上匹配（匹配条件为，一个字符串是另一个字符串的子集）。</p>
<p>最终获取的score除以eventtext触发词的数量（相当于取平均值），为最终的结果。</p>
<p>（注：最终获取的score除以eventtext的数量的目的在于通过平均值的方式降低因为文章长度而匹配次数更高，从而分数更高的情况）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_score</span>(<span class="params">eventtext, article_textrank, title_textrank</span>):</span></span><br><span class="line">    score = <span class="number">0.00000000000</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    score = float(score)</span><br><span class="line">    event_text_count = len(eventtext)</span><br><span class="line">    clean_eventtext = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> title_textrank:</span><br><span class="line">        <span class="keyword">for</span> et <span class="keyword">in</span> eventtext:</span><br><span class="line">            et = et.decode(<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">            et = et.strip(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">            et = et.strip(<span class="string">&#x27;\r&#x27;</span>)</span><br><span class="line">            et = str(et)</span><br><span class="line">            <span class="keyword">if</span> item.word <span class="keyword">in</span> model <span class="keyword">and</span> et <span class="keyword">in</span> model:</span><br><span class="line">                similarity = model.similarity(item.word, et)</span><br><span class="line">                <span class="keyword">if</span> similarity &gt;= <span class="number">0.5</span>:</span><br><span class="line">                    score = score + item.weight * similarity</span><br><span class="line">                    count = count + <span class="number">1</span></span><br><span class="line">                    clean_eventtext.append(et)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> item.word == et:</span><br><span class="line">                    score = score + item.weight</span><br><span class="line">                    count = count + <span class="number">1</span></span><br><span class="line">                    clean_eventtext.append(et)</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> article_textrank:</span><br><span class="line">        <span class="keyword">for</span> et <span class="keyword">in</span> eventtext:</span><br><span class="line">            et = et.decode(<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">            et = et.strip(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">            et = et.strip(<span class="string">&#x27;\r&#x27;</span>)</span><br><span class="line">            et = str(et)</span><br><span class="line">            <span class="keyword">if</span> item.word <span class="keyword">in</span> model <span class="keyword">and</span> et <span class="keyword">in</span> model:</span><br><span class="line">                similarity = model.similarity(item.word, et)</span><br><span class="line">                <span class="keyword">if</span> similarity &gt;= <span class="number">0.5</span>:</span><br><span class="line">                    score = score + item.weight * similarity</span><br><span class="line">                    count = count + <span class="number">1</span></span><br><span class="line">                    clean_eventtext.append(et)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">if</span> item.word == et:</span><br><span class="line">                    score = score + item.weight</span><br><span class="line">                    count = count + <span class="number">1</span></span><br><span class="line">                    clean_eventtext.append(et)</span><br><span class="line">    <span class="keyword">if</span> event_text_count == <span class="number">0</span>:</span><br><span class="line">        score = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        score = score / event_text_count</span><br><span class="line">    clean_eventtext = np.unique(clean_eventtext)</span><br><span class="line">    <span class="keyword">return</span> score, event_text_count, count, clean_eventtext</span><br></pre></td></tr></table></figure>



<p>若平均值为0则说明没有匹配上关键词，得分大小反映了关键词获取的质量。</p>
<p>最终以字典形式输出。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">form_dictionary</span>(<span class="params">name, score, event_text_count, article_textrank, count, eventtext, title_textrank, event_root, title, in_text</span>):</span></span><br><span class="line">    dict = &#123;&#125;</span><br><span class="line">    dict[<span class="string">&#x27;name&#x27;</span>] = str(name)</span><br><span class="line">    dict[<span class="string">&#x27;score&#x27;</span>] = str(score)</span><br><span class="line">    dict[<span class="string">&#x27;event_text_count&#x27;</span>] = str(event_text_count)</span><br><span class="line">    dict[<span class="string">&#x27;textrank_count&#x27;</span>] = str(len(article_textrank))</span><br><span class="line">    dict[<span class="string">&#x27;count&#x27;</span>] = str(count)</span><br><span class="line"></span><br><span class="line">    dict[<span class="string">&#x27;event_text&#x27;</span>] = str(eventtext)</span><br><span class="line">    textrank = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> article_textrank:</span><br><span class="line">        textrank.append(item.word)</span><br><span class="line">    dict[<span class="string">&#x27;textrank&#x27;</span>] = str(textrank)</span><br><span class="line">    title_textrank_new = []</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> title_textrank:</span><br><span class="line">        title_textrank_new.append(item.word)</span><br><span class="line">    dict[<span class="string">&#x27;title_textrank&#x27;</span>] = str(title_textrank_new)</span><br><span class="line">    event_root_new = []</span><br><span class="line">    <span class="keyword">for</span> er <span class="keyword">in</span> event_root:</span><br><span class="line">        et = er.decode(<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">        et = et.strip(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        et = et.strip(<span class="string">&#x27;\r&#x27;</span>)</span><br><span class="line">        et = str(et)</span><br><span class="line">        event_root_new.append(et)</span><br><span class="line">    dict[<span class="string">&#x27;event_root&#x27;</span>] = str(event_root_new)</span><br><span class="line"></span><br><span class="line">    dict[<span class="string">&#x27;title&#x27;</span>] = str(title)</span><br><span class="line">    dict[<span class="string">&#x27;text&#x27;</span>] = str(in_text.decode(<span class="string">&quot;utf-8&quot;</span>))</span><br><span class="line">    <span class="keyword">return</span> dict, event_root_new</span><br></pre></td></tr></table></figure>

<p>输出格式为：</p>
<p>name：文章名字（编号）</p>
<p>score：最终质量的评分（得分）</p>
<p>event_text_count：文章的eventtext的数量</p>
<p>count：匹配上了的次数的数量</p>
<p>textrank_count： textrank的数量</p>
<p>event_root： event_root</p>
<p>textrank：生成的textrank</p>
<p>title_textrank：题目的textrank</p>
<p>title：文章的题目</p>
<p>text：文章内容（包括题目）</p>
<p><img src="https://i.loli.net/2020/11/24/gZFsKjOfh8meMaX.png" alt="image-20201124190638749"></p>
<h1 id="4-伪代码"><a href="#4-伪代码" class="headerlink" title="4.伪代码"></a>4.伪代码</h1> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">SCREEN THE EVENT WITH HIGH QUALITY(event, eventtext)</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;1. model:</span><br><span class="line">def similarity(x,y)</span><br><span class="line">	x&#x3D;model.GetEmbedding(x)</span><br><span class="line">	y&#x3D;model.GetEmbedding(y)</span><br><span class="line">	return model.GetSimilarity(x,y)</span><br><span class="line"></span><br><span class="line">textrank &#x3D; GetTextRank(event)</span><br><span class="line">score &#x3D; 0</span><br><span class="line">count &#x3D; sizeof(eventtext)</span><br><span class="line">if similarity(eventtext, textrank) &gt; threshold:</span><br><span class="line">	score +&#x3D; similarity(eventtext, textrank) * textrank.value</span><br><span class="line">score &#x3D; socre&#x2F;count</span><br><span class="line">return score</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;2. dictionary:</span><br><span class="line">def similarity(x,y)</span><br><span class="line">	If getModelType(x) belongs to getModelType(y) or getModelType(y) belongs to getModelType(x):</span><br><span class="line">	return true</span><br><span class="line"></span><br><span class="line">textrank &#x3D; GetTextRank(event)</span><br><span class="line">score &#x3D; 0</span><br><span class="line">count &#x3D; sizeof(eventtext)</span><br><span class="line">If getModelType(x) belongs to getModelType(y) or getModelType(y) belongs to getModelType(x):</span><br><span class="line">	score +&#x3D; textrank.value</span><br><span class="line">score &#x3D; socre&#x2F;count</span><br><span class="line">return score</span><br></pre></td></tr></table></figure>

<h1 id="5-优化日志"><a href="#5-优化日志" class="headerlink" title="5.优化日志"></a>5.优化日志</h1><p>1、文字匹配的方式为单纯的字和字的匹配（是否是子集），同时最终score除以的是匹配的次数。</p>
<p>2、升级文字匹配的方式为词向量模型的方式。</p>
<p>3、升级文字匹配的方式为动词词典的方式。</p>
<p>4、升级，最终score除以的不再是匹配的次数，而是eventtext的次数，获得更加精确的判断。</p>
<p>如果除以匹配的次数，则会拉低某些匹配效果较好的得分（如：存在某个匹配效果极好，但是其他词语匹配效果一般的状况，这种情况若除以匹配的次数，则会将效果好的当作效果较差的）。所以除以eventtext的次数。同时这种方法能很好地处理某些语料存在eventtext不断重复的小问题。</p>
<p>5、升级，将表格里增加了eventtext的count的显示。</p>
<p>6、升级，将表格里增加了eventroot的显示。</p>
<p>7、升级，将文章的标题单独出来，提取标题的关键词，在原有的基础上，增加标题的关键词的权重。</p>
<p>经过大量的阅读和调查，发现人民日报的行文十分规范，故语料的结构相对较为清晰，语料的第一句提取出来即为该文章的标题。由于人民日报的标题专业性强，能很好地概括事件内容。故将文章的标题单独提取出来，增加文章内容的权重。根据以上匹配文章中关键词的方法，通过TextRank将文章标题提取出三个关键词出来，和eventtext进行匹配，若匹配成功，按照前文所述方式score加分，因而增加了文章的权重。</p>
<p>8、升级，将表格里增加了title，title的textrank的显示。</p>
<p>9、升级，改为通过文章的字数来判断textrank所获取的关键字的数量。</p>
<p>目前设置为1000字13个关键词起步，若增加/减少100字，则相应增加/减少1个TextRank的关键词。例如1924字的语料共提取22个TextRank关键词。</p>
<p>10、考虑尝试将source，target加入匹配中，但由于动词词典属于动词范围，而source和target从词性角度应为名词，故对于采取动词词典方式没有特别的影响。主要影响的是通过词向量模型的方式测试的效果。</p>
<h1 id="6-结果汇总"><a href="#6-结果汇总" class="headerlink" title="6.结果汇总"></a>6.结果汇总</h1><h2 id="6-1-人工标记"><a href="#6-1-人工标记" class="headerlink" title="6.1 人工标记"></a>6.1 人工标记</h2><p>最初采用相对盲目的选取语料方式进行打分，发现自己的打分范围不足以概括所有的情况，效果不尽如人意。</p>
<p>故采取第二种方式：由于项目数量相对较大，故在获取两组数据后，按照当前情况的得分进行排序，没100个中选择一个，即从35000条数据中获取350条数据，打乱顺序，人工手动打分（相对比较严格）。打分结束重新按照得分多少恢复数据。从而判断阈值。</p>
<h2 id="6-2-数据匹配与阈值筛选"><a href="#6-2-数据匹配与阈值筛选" class="headerlink" title="6.2 数据匹配与阈值筛选"></a>6.2 数据匹配与阈值筛选</h2><p>根据结果显示：</p>
<p>词向量模型的方法score不为0个数（匹配成功）为33247个。</p>
<p>动词词典的方法score不为0个数（匹配成功）为25990个。</p>
<p>比较了词向量模型的方式和动词字典的方式这两种方式，发现词向量模型的方式匹配的结果更加符合，相对而言动词词典存在不完整的情况，效果相对于词向量模型稍微差一些。</p>
<p>根据研究发现，以上现象的主要原因是动词词典的不完整，需要或者说可以进一步完善。</p>
<p>根据人工手动打分的比对，两者的结点的score取值的阈值为：</p>
<p>词向量模型：0.024</p>
<p>动词词典：0.0013</p>
<h2 id="6-3-两种方法结合"><a href="#6-3-两种方法结合" class="headerlink" title="6.3 两种方法结合"></a>6.3 两种方法结合</h2><p>故采取综合两种方法的方式，一种为两者得分相加，一种为两者求完阈值之后合并。</p>
<p>我对于两种方法皆进行了测试。</p>
<p>按照两者求完阈值之后合并，获得了24391条筛选之后的语料。于<strong>合并结果.txt</strong>中</p>
<p>两者相加得分的阈值为：0.03 ，共29967个。</p>
<h2 id="6-4-筛选结果"><a href="#6-4-筛选结果" class="headerlink" title="6.4 筛选结果"></a>6.4 筛选结果</h2><p>筛掉掉的语料中存在着不少触发词提取不准确的现象：</p>
<h2 id="6-4-1-新闻事件中评论过多，被认为是评论类新闻，实则不然。"><a href="#6-4-1-新闻事件中评论过多，被认为是评论类新闻，实则不然。" class="headerlink" title="6.4.1 新闻事件中评论过多，被认为是评论类新闻，实则不然。"></a>6.4.1 新闻事件中评论过多，被认为是评论类新闻，实则不然。</h2><p>举例：</p>
<p><strong>[‘010 作出评论 ‘]：</strong>载231人客机波兰迫降无人伤亡(组图)　　中新网11月2日电 据外电报道，当地时间1日，一架载有231人、从美国飞往波兰的客机由于发生机械故障，紧急迫降，所幸机上无人受伤。两架F-16战机升空护送客机。　　据报道，该架从美国纽瓦克机场飞往波兰华沙的波音767-35D型客机在准备着陆时起落架发生故障，无法正常打开，不得不在机场上空盘旋了1个小时，以释放掉客机多余的燃料，最后靠机身腹部迫降。　　一名波兰空军发言人说，得知情况后，空军方面派出两架F-1 6战斗机，升空护送客机，并提供相应协助。机场方面暂停所有航班起降，并在跑道上铺设了帮助迫降的材料。　　波兰TVN24新闻频道的画面显示，客机使用机身腹部迫降到地面，机腹部位出现一团白色泡雾状物，客机随后在跑道上滑行。　　据悉，该架客机上搭载着220名乘客和11名机组人员，事件没有造成人员受伤。　　客机降落后，乘客迅速撤离，消防车立即向客机洒水降温。该客机所属的波兰航空公司称，飞机之所以能够成功迫降，完全凭借飞行员高超的驾驶技术。据介绍，该名飞行员对波音客机有20年的飞行经验。　　波兰总统科莫罗夫斯基(Bronislaw Komorowski)对这架客机的飞行员及其它机组成员表示感谢，称赞他们在“危难时刻有效合作”。    </p>
<p><strong>[‘010 作出评论 ‘]：</strong>利比亚过渡委发现卡扎菲在苏尔特地下城堡(图)　　环球网实习记者赵小侠报道，据英国《每日电讯报》10月19日报道，利比亚“国家过渡委员会”在苏尔特一座被遗弃的住宅下发现了卡扎菲的地下城堡，利比亚当局官员表示，卡扎菲很有可能还在苏尔特城中。　　据报道，就像苏尔特的其他地方一样，卡扎菲昔日的豪宅现在已经成了一片废墟，豪华的装饰品遭到破坏，房间内现在满是瓦砾。利比亚“过渡委”士兵将记者带领至这片废墟下的“地下迷宫”，在这里，记者看到床垫还铺在地面上，这就是说最近这座地堡还有人住过。　　此前，“过渡委”指挥官曾表示，他85%的肯定卡扎菲、卡扎菲儿子穆塔西姆和其他卡扎菲政权高官仍藏匿于苏尔特。　　据悉，自从利比亚当局攻陷拜尼沃利德之后，苏尔特成了卡扎菲支持者占据的最后一座城市。“过渡委”最近正式宣布，只有苏尔特得以完全解放，才会为成立完善的政府、创造一个民主国家铺平道路。    </p>
<h2 id="6-4-2-触发词提取不准确，不具备独特性。"><a href="#6-4-2-触发词提取不准确，不具备独特性。" class="headerlink" title="6.4.2 触发词提取不准确，不具备独特性。"></a>6.4.2 触发词提取不准确，不具备独特性。</h2><p>举例：</p>
<p><strong>[‘064 共享信息 ‘]：</strong>巴基斯坦海军宣传照错印印度战舰(图)　　环球网记者仲伟东报道，《印度时报》3月9日消息称，巴基斯坦海军8日公布的多国海军联合军演宣传照“出岔子”，并未参加该次演习的印度海军军舰的形象竟然出现在宣传照上，“让人啼笑皆非”。　　报道说，这幅宣传照印有“携手为和平”的宣传口号，旨在宣传代号“阿曼-11”的联合演习，照片上还印有印度海军的“戈达瓦里”级和“塔尔瓦”级战舰的图像。报道指出，该宣传照上的美印军舰形象，可能来自2010年“马拉巴尔”美印海军联合演习时所用的宣传照。目前巴基斯坦海军暂未对此事发表评论。　　报道介绍称，将有来自39个国家的战舰、战机、特种部队和代表参加该次演习，演习旨在促进该地区和平，并打击该地区的海上威胁。　　《印度时报》同时指出，这并非印巴两国首次“摆乌龙”。去年3月，巴基斯坦旁遮普省警方公布的一幅宣传照上，竟然印有印度旁遮普警察的标志。而在去年1月份的一幅印度政府宣传照中，巴基斯坦前空军参谋长坦维尔?艾哈迈德居然和印度总理辛格站在一起。    </p>
<h2 id="6-4-3-由于语义的关系，没有正确识别情感取向，错将相反的情感取向提取。"><a href="#6-4-3-由于语义的关系，没有正确识别情感取向，错将相反的情感取向提取。" class="headerlink" title="6.4.3 由于语义的关系，没有正确识别情感取向，错将相反的情感取向提取。"></a>6.4.3 由于语义的关系，没有正确识别情感取向，错将相反的情感取向提取。</h2><p>举例：</p>
<p><strong>[‘090 期望人道主义救援 ‘]：</strong>日本核污水或将污染海洋生物链　　如今人们并不清楚福岛附近海域都有哪些鱼类，会如何迁徙。如果鱼类在污染区停留时间很长，那么通过食物链富集到鱼体内的铯可能会形成污染　　《国际先驱导报》记者蓝建中、金微发自东京、北京从5级直接升到最高的7级，当4月12日，日本经济产业省原子能安全保安院与原子能安全委员会正式宣布，将福岛第一核电站事故的严重程度“连升两级”后，对于福岛的核泄漏是否会超过切尔诺贝利的担心开始多了起来。　　由于事故仍然处于进行时，东京电力公司干部松本纯一甚至指出：“现在仍担心泄漏量有可能与切尔诺贝利相匹敌，甚至还会超越切尔诺贝利事故。”　　而最让人担心的，就是福岛核电站流出的污水。　　日本民众的愤怒和恐慌　　在周半国家的抗议和不满声中，4月10日，日本终于停止了向大海排放放射性核废水，6天时间，1.15万吨相当于4个奥运标准泳池的低浓度放射污染废水排入海中。　　这些放射性废水对大海造成什么影响尚难以估量，但恐慌和担忧情绪已在日本国内蔓延。　　东京的大型超市里，购买鲜鱼时犹豫不决的顾客越来越多。不仅如此，商家在核电站事故之前采购的咸鱼和干鱼都有些滞销，他们只能想办法促销。一些寿司店表示，自从福岛核事故以来，他们不断被顾客询问安全性问题。　　实际上，对于东电公司和日本政府的向海里排污的举动，日本民众从开始就感到震惊和愤怒。不满的声音首先从日本渔业传出，福岛县渔业协同组合联合会参事小野修司指出：“东京电力公司是在开始排放前两个小时才通知联合会的，根本没有时间向渔民进行解释。”　　“我手头要是有水的话，非得泼在东电总裁的脸上。卖不出去的鱼要他们赔！”茨城县渔民武子宽一脸无奈又愤怒地说。　　日本茨城县渔业协会宣布，从附近海域捕捞的海鱼被检测出放射性物质超标，受此影响，中国上海、广东、浙江等地的海产品交易量下降。中国官方在4月9日扩大了禁止从日本进口食品的品种和产地范围。　　东电没有说明这些废水的放射性浓度数值，只是强调说这是“低浓度的放射性污水”。按《核反应堆规制法》的相关规定，低浓度核污染污水通常指比普通海水中的辐射浓度高出100倍的污染水，但东电说的“低浓度核污染污水”显然并不是这样的准确的科学术语。　　“放射性浓度多少不知道，里面究竟含有哪些成份也不清楚，除了放射性物质，还可能存在其他东西。”复旦大学核科学与技术系副主任陈建新告诉《国际先驱导报》，日本方面提供的信息相当不透明。　　随着洋流扩散　　世界气象组织和国际原子能机构北京区域环境紧急响应中心高级工程师周斌对于核废水在海洋中的扩散作了一个形象的比喻：“好比墨水滴入一条河流，墨水的扩散是向周围不断稀释，并且向下游运动，下游浓度不断衰减。”　　进入大海的核废水会除了部分沉淀，还有一部分会随洋流运动。　　福岛附近海域是千岛寒流和黑潮相遇的地方，也是著名的渔场，两股洋流在这里相会后，继续北上，形成太平洋暖流，流到阿拉斯加和加拿大，继续南下到美国和墨西哥以后，又沿着赤道西流，最后流回马来群岛和中国台湾附近。　　从洋流的角度看，福岛核电站泄漏或排出的核辐射污染水体，主要被黑潮带动向西北和东北太平洋一侧扩散。　　法国国家科学研究院受国际原子能机构委托，根据福岛县海域的海底地形、潮流、水温、盐分浓度等，预测了放射性物质的扩散。结果发现，放射性物质最初会沿着海岸向南北扩散，到了北方的仙台湾以后，将会向东西方向扩散。正因为如此，虽然有来自马来群岛附近的强大黑潮从日本列岛附近向北流过，福岛县以南的茨城县也依然有鱼类被检测出放射性物质超标。　　“大气环流的的运动，一般２～３个星期就会绕地球一圈，而核放射性物质随大气环流扩散的周期比这更长一些。”周斌说，“在这过程中，由于路径长，以及空气阻力、降水沉降和自身衰减等多方影响，放射性物质在不断稀释，浓度就会不断减小。”　　日本方面的说法称，1.15万吨低浓度核废水排入大海后，洋流会把污染物稀释至原本的1％。　　而周斌认为，通过大气扩散模式计算，假如放射性物质在原地的浓度为１个单位，那么经过大气环流运动，扩散到我国后的浓度仅为１０的负２５次方左右。因此不用担心核废水对我国海域的影响。　　污染取决于水的流动　　在所排放的核废水中，放射性元素主要是碘和铯，由于放射性元素半衰期的时间长短不同，危害也不一样。碘-131的放射性半衰期是8天，经过10个半衰期，它的放射性会大大减少，危险可以忽略不计，因此参与洋流运动的放射性物质主要是铯。　　日本原子能研究开发机构研究员中野政尚曾对半衰期约为30年的放射性铯从茨城县海域扩散的情形进行过计算机模拟演算，结果发现放射性铯顺着海流，5年后将到达北美，10年后回到亚洲东部，30年后几乎扩散到整个太平洋。不过，他认为，即使泄漏2万吨高放射性污水，放射性活度在1年后也将稀释到每升约1贝克勒尔，10年后将不到0.1贝克勒尔，其水平不会对人体造成影响。　　切尔诺贝利事故后，国际一些机构的研究表明，受放射性污染较严重的是封闭水体，如湖泊，而不是河流和海洋。俄罗斯科学院曾比较了不同污染地区的淡水鱼肌肉组织中的铯-137含量，发现河流中的鱼受到的污染比湖泊中的鱼要轻。　　德国负责渔业环境放射污染监测的约翰·海因里希·冯·杜能研究所也发表公报说，根据切尔诺贝利核事故取得的经验，福岛核电站泄漏的放射性物质不会对鱼类等海洋生物造成长期污染。该研究所指出，切尔诺贝利核事故发生后，德国在过去25年中持续监测该事故的放射性污染物对邻近的大西洋和波罗的海鱼类的影响，发现放射性污染物在水流循环好的海域很快会被稀释。事故发生后第二年，德国有关海域就已检测不到核事故造成的铯污染。　　没有被稀释的　　由于海的容量巨大，放射物除了被海水稀释，也有相当一部分会沉降到海底。　　虽然日本方面一再强调这些污水对鱼类的影响有限，但是香港城市大学生物及化学系副教授林汉华称，很多废水会留在近岸，污染悬浮物质，当悬浮物质沉积到海底，会污染整个海床，慢慢传播到整条食物链。　　法国辐射防护与核安全研究院以海流数据等为基础进行计算机模拟演算，得出结论：以微粒形式沉淀在海底的放射性物质有可能造成长期污染。特别是铯-134的半衰期为数年，铯-137的半衰期为约３０年，有可能沉淀的日本海岸地区，需要长期进行监控。　　该机构指出，放射性物质还有可能在鱼类和贝类体内富集。这里指的是“生物富集”，比如自然界中一种有害的化学物质被草吸收，浓度很低，以吃草为生的兔子吃了这种草，因这种有害物质很难排出体外，便逐渐在它体内积累。老鹰以吃兔子为生，于是有害的化学物质便会在老鹰体内进一步积累。食物链对有害的化学物质有累积和放大的效应。　　如果是放射性的铯，在软体动物和海藻中的富集率是50倍，但是在鱼类中则会富集400倍。放射性碘则相反，在鱼类体内会富集15倍，海藻中是1万倍。　　根据放射性物质与生物种类的不同，污染的状况也多种多样。海带等被放射性碘-131污染的危险很大，但是碘-131的半衰期很短，所以有重大危险也只停留在几个月之内。　　切尔诺贝利事故后也表明，对于食物的影响主要是铯，它会随着食物链传递和富集，因此捕食性的鱼类肌肉组织中或许随着时间推移会有更多的放射物。　　英国普斯茅斯大学环境学家吉姆·史密斯认为，如今人们并不清楚福岛附近海域都有哪些鱼类，会如何迁徙。如果鱼类在污染区停留时间很长，那么通过食物链富集到鱼体内的铯可能会形成污染。　　更让人担心的　　在低浓度核污染废水进入大海之前，日本已经发生了一次核辐射污水泄漏事件。含高浓度辐射物质积水从日本福岛2号机组的裂缝渗入太平洋，导致机组附近海水中中含有超过法定限度７５０万倍的放射性碘，当地水产品也被严重污染。　　“这些从反应堆地底下渗透到海洋里的污水才是最大的担忧，这里面不单单是碘、铯放射物，还可能包括像破碎棒等物质，这些东西对人体会造成什么危害现在也说不清楚。”陈建新说。　　如今，日本开始着手转移积存在福岛第一核电站2号机组汽轮机厂房附近竖井内的高放射性污水。这些积水正被转移到该厂房内一个容量约为3000吨的空置冷凝器中。　　据估计，福岛第一核电站1号至3号机组涡轮机房地下室以及机组外隧道和竖井内，至少存有6万吨高放射性污水，这3000吨的存储容量显然是杯水车薪。不过，鉴于2号机组问题最为严重：其积水表面辐射量非常高，在此环境中工作4小时即可致人死亡。同时，竖井内的污水4月10日上午已升至距地表92厘米，若再不及时转移，有可能溢出。　　但是对于其余的高放射性污水的处理方法，日本方面尚未拿出方案。　　目前，日本福岛核电站附近海洋已被严重污染已是事实。美国国家地理网站称，福岛核电站附近的放射性污染对当地海洋动物的生存造成伤害。放射生态学家沃德·维克勒说，海洋动物的卵和幼体对辐射较为敏感，所导致的辐射暴露将改变它们的DNA。　　陈建新认为，现在断定日本核污水对中国无影响还为时尚早，“日本的近海的一些水产品，包括小鱼大鱼，如果最后流到我们的餐桌上，我们吃了这些东西显然也会被污染。”　　《国际先驱导报》法律声明：本报记者及特约撰稿人授权本报声明：本报所刊其撰写的稿件和提供的图片，未经本报许可，不得转载、摘编（有需转载者请致电至010—63073377或发邮件至<a href="mailto:&#x69;&#104;&#x6c;&#x2d;&#109;&#x61;&#x72;&#107;&#x65;&#116;&#64;&#118;&#105;&#x70;&#x2e;&#115;&#x69;&#110;&#x61;&#x2e;&#99;&#x6f;&#109;">&#x69;&#104;&#x6c;&#x2d;&#109;&#x61;&#x72;&#107;&#x65;&#116;&#64;&#118;&#105;&#x70;&#x2e;&#115;&#x69;&#110;&#x61;&#x2e;&#99;&#x6f;&#109;</a>）    </p>
<p><strong>[‘026 期望协商 ‘]：</strong>美刊称中期选举后新孤立主义将主导美国外交　　环球时报特约记者宋华报道 据美国《新闻周刊》10月23日发表分析文章称，中期选举后，是冷淡而不是激进主义将主导美国外交政策。文章认为，由于美国国内面临严重的经济和失业问题，选民不再关心外部世界所发生的事情，而各党候选人也投其所好，有意避开外交问题而大谈经济。而由于经济问题很难在短期内解决，因此这种新孤立主义的“冷淡”将在较长时间里影响美国外交。　　美国人对世界事务趋向冷淡　　文章称，在美国各党竞选辩论或者候选人的言论中，竞选广告里，阿富汗很少被提及，伊拉克战争已是历史，中东和平会谈进展会让人打呵欠。忘记拉丁美洲吧，俄罗斯已是一个古老的回忆，欧洲正在从美国人的视线中消失。一些候选人很负责任地记住了相关话题的发言要点，但许多候选人并没有那样作。当选民们被问及美国最为迫切的问题是什么时，只有3%的人回答说是阿富汗，60%的人称是经济和失业问题。　　一些政治家都对这种态度感到震惊。来自南卡罗莱纳州的共和党参议员林赛?格雷厄姆最近在华盛顿称：“任何候选人——茶党、共和党人、素食主义者、自由主义者、民主党人就我们应该对伊朗采取什么措施进行过认真的讨论吗？你看到一个有关阿战战略是好还是坏的电视竞选广告吗？你将永远无法知道这个国家正在打两场战争，我们所面临的威胁可能影响人类的走向。我不能理解的是，这种情况是如何发生的？”　　分析称，这种冷淡深深植根于这个移民国家：移民们前往美国是为了逃避冲突和贫穷。美国人传统上是以未来生活为导向的，不愿意承担过去的负担，他们不想从他们的任务中分心。今天，理解美国公众对全球事务更加缺乏兴趣是至关重要的，因为冷淡而不是激进主义将在可预期的未来引导或者限制、干扰美国政府的行动。　　美国领导人的挑战　　俄亥俄大学政治学教授约翰?米勒称，美国公众舆论中一直存在着某种橡皮带效应，公众关注的焦点总是会反弹至国内的关切。他根据多年的民调数据得出结论认为，公众的注意力可以被重大事件或者对美国人生命的具体、重大威胁所吸引，但当这些担心被缓解后，人们就会把关注点转回国内议题。米勒称，对于那些担心外国事务的国内外人士来说，“这种倾向可能就像是一种注意力不足症。”　　对美国领导人的挑战一直是抵制这种倾向。奥巴马是有史以来国际背景知识最丰富的美国领导人，他明白与世界接触的必要性。奥巴马就任时不仅承诺要行使全球的领导力，而且要与盟友结成伙伴、向敌人伸出手。如果正如许多人所预料的那样，奥巴马的民主党失去对众议院的控制，只在参议院保住微弱优势的话，奥巴马争取对外交倡议支持的能力将进一步被削弱。与伊朗和其它对美国持敌视态度的国家进行对话的希望可能被国会山上对立的多数派成员破坏。　　文章认为，多数情况下，美国公众的普遍冷淡是一种任性的无知。当暴怒横行而理性处于撤退的时期，没有人想听包括总统在内的政策书呆子来讲述复杂的外交事务。在竞选期间，“海外”是愤世嫉俗商人把工作岗位输出的地方或者是无能的现任官员放任这种现象发生的地方，或者两者兼有。与此同时，数百万移民或者是非法移民正来到美国，来夺占本来已经很少的工作岗位。在这一竞选季节，整个世界被分化成“他们”和“我们”，“他们”并没有发言权或者选票。　　忽视世界的危险　　文章表示，美国人忽视世界的倾向并不真的是一件政党政治事务或者是传统的左右翼分歧。自由派经济学家、前克林顿政府时期劳工部长罗伯特?赖克写道：“我们正处在新孤立主义的边缘，新孤立主义将伤害我们所有的人。”他指责右翼的茶党和左翼的工会赞成保护主义。正如赖克所说的那样，这可能“导致对自由贸易、移民、甚至世贸组织、世界银行和国际货币基金组织这样的国际机构的强烈抵制。”与此同时，美国企业研究所的保守派分析人士普雷卡则对公众对保护全球各地自由事业兴趣的下降发出哀叹。她警告称，美国从世界事务中后撤将堕落为一个清算中心，所有的事情都沦落为美元和美分。　　美国人在过去的许多时候也曾陷入这种冷淡但是情绪化的状态，这方面的记录是悲惨的。在第一次世界大战后，美国退出了国联，结果只是看到纳粹在德国的崛起。在冷战结束后，美国赢得了海湾战争，历史看上去于九十年代初期结束了，民主党人克林顿以“这是经济，笨蛋。”的口号赢得了总统选举。美国公众在这之后几乎完全没有对世界其它地方发生的巨大灾难有所触动。在对索马里进行短暂和血腥的干涉后，美国从索马里后退，放任其陷入混乱，然后很快忘记了这一切。就在“9?11”事件发生不久之前的2001年夏季，民调显示，恐怖主义在美国公众担心的事务排名最后。正如格雷厄姆参议员所说的那样，有时候，只有重大事件的发生才能使美国的注意力聚焦。    </p>
<h1 id="7-实验室其他学习成果"><a href="#7-实验室其他学习成果" class="headerlink" title="7.实验室其他学习成果"></a>7.实验室其他学习成果</h1><p>除了核心内容外还学习了其他相关内容，同时跑了甚至一点点实现了相关代码。如TextCNN，基本的GAN网络，Ziyun词云等等。</p>
<h2 id="7-1-TextCNN"><a href="#7-1-TextCNN" class="headerlink" title="7.1 TextCNN"></a>7.1 TextCNN</h2><p>TextCNN对于日后的帮助主要在于了解词向量的概念，同时了解如何将词语变成词向量，同时巩固了卷积神经网络的概念。项目采用的是清华大学开源的标题分类的数据，初步了解NLP。具体内容参见个人学习博客。</p>
<p>TextCNN个人学习博客：<a href="https://shijiasheng.top/2020/10/15/TextCNN/">https://shijiasheng.top/2020/10/15/TextCNN/</a></p>
<h2 id="7-2-Ziyun"><a href="#7-2-Ziyun" class="headerlink" title="7.2 Ziyun"></a>7.2 Ziyun</h2><p>依托于软工项目，调用库将关键词信息反映在图象上。</p>
<p><img src="https://i.loli.net/2020/12/22/Izxmu5YBJ6kZP1q.png" alt="image-20201222200432658"></p>
<h2 id="7-3-flask"><a href="#7-3-flask" class="headerlink" title="7.3 flask"></a>7.3 flask</h2><p>python的前端制作，学习相关知识。</p>
<h1 id="8-文件说明"><a href="#8-文件说明" class="headerlink" title="8.文件说明"></a>8.文件说明</h1><p>1、其他</p>
<p>1.csv：词向量模型与人工比对结果</p>
<p>2.csv：动词字典与人工比对结果</p>
<p>3.csv：合并结果与人工比对结果</p>
<p>测试.txt：人工测试的数据</p>
<p>动词字典.csv：动词字典</p>
<p>动词字典.txt：动词字典</p>
<p>测试：所有的语料重新编号</p>
<p>石稼晟有效人工判断.csv：手动判断</p>
<p>2、csv为所有文件，txt为筛选所得的编号，编号对应<strong>测试文件夹</strong>的序号</p>
<p>词向量模型结果.csv</p>
<p>词向量模型结果.txt</p>
<p>词向量模型结果.csv</p>
<p>词向量模型结果.txt</p>
<p>合并结果.csv</p>
<p>合并结果.txt</p>
<p>3、TextRank4ZH-master：代码的内容</p>
<p>TextRank4ZH-master</p>
<p>├─contract<br>├─example<br>├─test<br>│  └─doc<br>└─textrank4zh</p>
<p>NLP\TextRank4ZH-master\example\create_dictionary.py：创建动词字典代码</p>
<p>NLP\TextRank4ZH-master\example\create_model.py创建词向量模型代码</p>
<p>NLP\TextRank4ZH-master\example\word2vec.model生成的词向量模型</p>
<p>NLP\TextRank4ZH-master\example\final_text.py最终测试代码</p>
<p>NLP\TextRank4ZH-master\example\shaixuan.py筛选每100条选1条数据代码</p>
<p>NLP\TextRank4ZH-master\example\union.py合并测试代码</p>
<p>NLP\TextRank4ZH-master\test\ziyun_test.py字云代码</p>
<p>NLP\TextRank4ZH-master\textrank4zh\stopwords.txt停用词文档</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">Author: </span><span class="post-copyright-info"><a href="mailto:undefined">Shi Jiasheng</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">Link: </span><span class="post-copyright-info"><a href="http://shijiasheng.top/2021/01/11/SoftwareEngineering/">http://shijiasheng.top/2021/01/11/SoftwareEngineering/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> Donate<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://i.loli.net/2020/10/17/e6mO8QiDPLAofp3.png" target="_blank"><img class="post-qr-code-img" src="https://i.loli.net/2020/10/17/e6mO8QiDPLAofp3.png" alt="wechat"/></a><div class="post-qr-code-desc">wechat</div></li><li class="reward-item"><a href="https://i.loli.net/2020/10/17/wMNrWVGY1ETSHsp.jpg" target="_blank"><img class="post-qr-code-img" src="https://i.loli.net/2020/10/17/wMNrWVGY1ETSHsp.jpg" alt="alipay"/></a><div class="post-qr-code-desc">alipay</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2021/04/28/MATLAB%20Install%20Tutorial%20in%20Linux/"><img class="prev-cover" src="https://i.loli.net/2021/04/28/BEPQuvh8YAsHiZV.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Previous Post</div><div class="prev_info">MATLAB Install Tutorial in Linux</div></div></a></div><div class="next-post pull-right"><a href="/2020/11/05/TextRank/"><img class="next-cover" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">Next Post</div><div class="next_info">TextRank</div></div></a></div></nav><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> Comment</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></article></main><footer id="footer" style="background-image: url(https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/img/default.jpg)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Shi Jiasheng</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><section id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Switch Between Light And Dark Mode"><i class="fas fa-adjust"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="Setting"><i class="fas fa-cog"></i></button><a id="to_comment" href="#post-comment" title="Scroll To Comments"><i class="fas fa-comments"></i></a><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><i class="fas fa-arrow-up"></i></button></div></section><div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',()=> {preloader.endLoading()})</script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const initData = {
      el: '#vcomment',
      appId: 'zvvoDGrhJD618lRWiUiEbxGN-gzGzoHsz',
      appKey: '8kj91haHbuc5Wn7fwm8sKDeK',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
    }

    if (true) { 
      initData.requiredFields= ('nick,mail'.split(','))
    }

    const valine = new Valine(initData)
  }

  if (typeof Valine === 'function') initValine() 
  else $.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js', initValine)
}

if ('Valine' === 'Valine' || !true) {
  if (true) btf.loadComment(document.querySelector('#vcomment'),loadValine)
  else setTimeout(() => loadValine(), 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script></div></body></html>